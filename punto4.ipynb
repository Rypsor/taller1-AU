{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5eafa4f4",
   "metadata": {},
   "source": [
    "# Predicción de Riesgo de Accidentes con Ensamble Stacking ( Ejecutado en Kaggle notebook )\n",
    "\n",
    "### Resumen del Proceso\n",
    "\n",
    "Este notebook aborda el problema de predecir el riesgo de accidentes de tráfico. La estrategia principal se centra en la **aumentación de datos y el modelado con un ensamble de stacking** para maximizar la precisión.\n",
    "\n",
    "El flujo de trabajo se divide en los siguientes pasos clave:\n",
    "\n",
    "1.  **Aumentación de Datos**: Para robustecer el entrenamiento, duplicamos el tamaño del dataset de entrenamiento. Creamos una copia **sintética** de los datos originales ( ya que se conoce el generador de datos que sirvió como base para los datos de la competencia), generando un nuevo `accident_risk` basado en una fórmula predefinida que imita las relaciones lógicas entre las variables. Luego, combinamos los datos reales y los sintéticos.\n",
    "\n",
    "2.  **Ingeniería de Características**: Se crean nuevas variables informativas a partir de las existentes para mejorar la capacidad predictiva de los modelos. Esto incluye:\n",
    "    * `base_risk`: Un cálculo de riesgo utilizado en el generador de datos, así que es una característica muy importante.\n",
    "    * `speed_per_lane`: Una interacción entre el límite de velocidad y el número de carriles.\n",
    "    * `adverse_conditions`: Una bandera que indica si las condiciones climáticas o de iluminación son desfavorables.\n",
    "\n",
    "3.  **Preprocesamiento y Pipelines**: Las características categóricas se transforman con `OneHotEncoder` y las numéricas se escalan con `StandardScaler`. Todo el proceso se encapsula en `Pipelines` de Scikit-learn para un flujo de trabajo limpio y eficiente.\n",
    "\n",
    "4.  **Modelado y Ensamble**:\n",
    "    * **Modelos Base**: Se entrenan y evalúan tres potentes modelos de gradient boosting: **XGBoost, LightGBM y CatBoost**.\n",
    "    * **Ensamble Stacking**: Para la predicción final, se construye un `StackingRegressor`. Este \"modelo de modelos\" utiliza las predicciones de los tres modelos base como entrada para un meta-modelo final (`Ridge`), que aprende a combinarlas de la manera más óptima.\n",
    "\n",
    "5.  **Evaluación y Predicción Final**: Todos los modelos, incluidos los base y el ensamble final, se evalúan rigurosamente mediante **validación cruzada de 5 folds** para estimar su rendimiento real (RMSE). Finalmente, el ensamble de stacking se entrena con todos los datos y se utiliza para generar el archivo `submission.csv` para la competencia. También se genera un reporte (`rendimiento_modelos.txt`) con los resultados comparativos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aead34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================================\n",
    "# CELDA 2: GENERACIÓN DE DATOS SINTÉTICOS Y DATASET COMBINADO\n",
    "# =========================================================================\n",
    "\n",
    "# --- 1. Función Original para Generar Datos Sintéticos ---\n",
    "# Mantenemos tu función original intacta.\n",
    "def generate_synthetic_data(num_rows=10000, seed=42,\n",
    "                            road_type=None, num_lanes=None, curvature=None,\n",
    "                            speed_limit=None, lighting=None, weather=None,\n",
    "                            road_signs_present=None, public_road=None,\n",
    "                            time_of_day=None, holiday=None, school_season=None,\n",
    "                            num_reported_accidents=None):\n",
    "    np.random.seed(seed)\n",
    "    data = {\n",
    "        \"road_type\": road_type if road_type is not None else np.random.choice([\"highway\", \"urban\", \"rural\"], num_rows),\n",
    "        \"num_lanes\": num_lanes if num_lanes is not None else np.random.randint(1, 5, num_rows),\n",
    "        \"curvature\": curvature if curvature is not None else np.round(np.random.uniform(0.0, 1.0, num_rows), 2),\n",
    "        \"speed_limit\": speed_limit if speed_limit is not None else np.random.choice([25, 35, 45, 60, 70], num_rows),\n",
    "        \"lighting\": lighting if lighting is not None else np.random.choice([\"daylight\", \"night\", \"dim\"], num_rows),\n",
    "        \"weather\": weather if weather is not None else np.random.choice([\"clear\", \"rainy\", \"foggy\"], num_rows),\n",
    "        \"road_signs_present\": road_signs_present if road_signs_present is not None else np.random.choice([True, False], num_rows),\n",
    "        \"public_road\": public_road if public_road is not None else np.random.choice([True, False], num_rows),\n",
    "        \"time_of_day\": time_of_day if time_of_day is not None else np.random.choice([\"morning\", \"evening\", \"afternoon\"], num_rows),\n",
    "        \"holiday\": holiday if holiday is not None else np.random.choice([True, False], num_rows),\n",
    "        \"school_season\": school_season if school_season is not None else np.random.choice([True, False], num_rows),\n",
    "        \"num_reported_accidents\": num_reported_accidents if num_reported_accidents is not None else np.random.poisson(lam=1.5, size=num_rows)\n",
    "    }\n",
    "    base_risk = (\n",
    "        0.3 * np.array(data[\"curvature\"]) +\n",
    "        0.2 * (np.array(data[\"lighting\"]) == \"night\").astype(int) +\n",
    "        0.1 * (np.array(data[\"weather\"]) != \"clear\").astype(int) +\n",
    "        0.2 * (np.array(data[\"speed_limit\"]) >= 60).astype(int) +\n",
    "        0.1 * (np.array(data[\"num_reported_accidents\"]) > 2).astype(int)\n",
    "    )\n",
    "    noise = np.random.normal(0, 0.05, num_rows)\n",
    "    risk_score = np.clip(base_risk + noise, 0, 1)\n",
    "    data[\"accident_risk\"] = np.round(risk_score, 2)\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# --- 2. Creación del Dataset Combinado (Lógica Original) ---\n",
    "print(\"Generando datos sintéticos para el set de entrenamiento...\")\n",
    "synthetic_train_df = generate_synthetic_data(\n",
    "    num_rows=train_df_raw.shape[0], seed=42, road_type=train_df_raw[\"road_type\"],\n",
    "    num_lanes=train_df_raw[\"num_lanes\"], curvature=train_df_raw[\"curvature\"],\n",
    "    speed_limit=train_df_raw[\"speed_limit\"], lighting=train_df_raw[\"lighting\"],\n",
    "    weather=train_df_raw[\"weather\"], road_signs_present=train_df_raw[\"road_signs_present\"],\n",
    "    public_road=train_df_raw[\"public_road\"], time_of_day=train_df_raw[\"time_of_day\"],\n",
    "    holiday=train_df_raw[\"holiday\"], school_season=train_df_raw[\"school_season\"],\n",
    "    num_reported_accidents=train_df_raw[\"num_reported_accidents\"])\n",
    "\n",
    "train_df_raw['synthetic_risk'] = synthetic_train_df['accident_risk']\n",
    "\n",
    "train_real_df = train_df_raw.copy()\n",
    "train_real_df['is_synthetic'] = 0\n",
    "\n",
    "train_synthetic_df = train_df_raw.drop(columns=['accident_risk']).copy()\n",
    "train_synthetic_df.rename(columns={'synthetic_risk': 'accident_risk'}, inplace=True)\n",
    "train_synthetic_df['is_synthetic'] = 1\n",
    "\n",
    "combined_train_df = pd.concat([train_real_df.drop(columns=['synthetic_risk']), train_synthetic_df], ignore_index=True)\n",
    "combined_train_df = combined_train_df.sample(frac=1, random_state=42).reset_index(drop=True) \n",
    "\n",
    "print(f\"✅ Dataset de entrenamiento combinado creado: {combined_train_df.shape}\")\n",
    "\n",
    "# --- 3. Añadir Features Sintéticas al Dataset de Test ---\n",
    "print(\"\\nGenerando datos sintéticos para el set de test...\")\n",
    "synthetic_test_df = generate_synthetic_data(\n",
    "    num_rows=test_df_raw.shape[0], seed=42, road_type=test_df_raw[\"road_type\"],\n",
    "    num_lanes=test_df_raw[\"num_lanes\"], curvature=test_df_raw[\"curvature\"],\n",
    "    speed_limit=test_df_raw[\"speed_limit\"], lighting=test_df_raw[\"lighting\"],\n",
    "    weather=test_df_raw[\"weather\"], road_signs_present=test_df_raw[\"road_signs_present\"],\n",
    "    public_road=test_df_raw[\"public_road\"], time_of_day=test_df_raw[\"time_of_day\"],\n",
    "    holiday=test_df_raw[\"holiday\"], school_season=test_df_raw[\"school_season\"],\n",
    "    num_reported_accidents=test_df_raw[\"num_reported_accidents\"])\n",
    "\n",
    "test_df = test_df_raw.copy()\n",
    "test_df['synthetic_risk'] = synthetic_test_df['accident_risk']\n",
    "test_df['is_synthetic'] = 0 # El test siempre es \"real\"\n",
    "\n",
    "print(f\"✅ Features sintéticas añadidas al dataset de test: {test_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb58798",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================================\n",
    "# CELDA 3: ING. DE CARACTERÍSTICAS Y DEFINICIÓN DE PIPELINES BASE\n",
    "# =========================================================================\n",
    "import lightgbm as lgb\n",
    "import catboost as cb\n",
    "\n",
    "# --- 1. Función para Crear Nuevas Características ---\n",
    "def feature_engineer(df):\n",
    "    df_eng = df.copy()\n",
    "    df_eng['base_risk'] = (\n",
    "        0.3 * df_eng[\"curvature\"] +\n",
    "        0.2 * (df_eng[\"lighting\"] == \"night\").astype(int) +\n",
    "        0.1 * (df_eng[\"weather\"] != \"clear\").astype(int) +\n",
    "        0.2 * (df_eng[\"speed_limit\"] >= 60).astype(int) +\n",
    "        0.1 * (df_eng[\"num_reported_accidents\"] > 2).astype(int)\n",
    "    )\n",
    "    df_eng['speed_per_lane'] = df_eng['speed_limit'] / df_eng['num_lanes']\n",
    "    df_eng['adverse_conditions'] = ((df_eng['weather'] != 'clear') | (df_eng['lighting'] != 'daylight')).astype(int)\n",
    "    return df_eng\n",
    "\n",
    "print(\"Aplicando ingeniería de características...\")\n",
    "X_full = feature_engineer(combined_train_df.drop(columns=['id', 'accident_risk']))\n",
    "y_full = combined_train_df['accident_risk']\n",
    "X_test_full = feature_engineer(test_df.drop(columns=['id']))\n",
    "print(\"✅ Ingeniería de características completada.\")\n",
    "\n",
    "\n",
    "# --- 2. Definición Final de Tipos de Características ---\n",
    "cat_features = X_full.select_dtypes(include=[\"object\", \"bool\"]).columns.tolist()\n",
    "num_features = X_full.select_dtypes(include=[\"int64\", \"float64\", \"int32\"]).columns.tolist()\n",
    "print(f\"\\nCaracterísticas categóricas ({len(cat_features)}): {cat_features}\")\n",
    "print(f\"Características numéricas ({len(num_features)}): {num_features}\")\n",
    "\n",
    "\n",
    "# --- 3. DEFINICIÓN DE PIPELINES BASE ---\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_features),\n",
    "        (\"num\", StandardScaler(), num_features)\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "# Modelo 1: XGBoost\n",
    "xgb_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor), \n",
    "    ('regressor', xgb.XGBRegressor(\n",
    "        n_estimators=2000, learning_rate=0.02, max_depth=7, \n",
    "        subsample=0.8, colsample_bytree=0.8,\n",
    "        objective='reg:squarederror', tree_method='hist', device='gpu', random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Modelo 2: LightGBM (El Rápido y Generalista)\n",
    "# Menos profundo para capturar señales generales y evitar sobreajuste en detalles.\n",
    "lgbm_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor), \n",
    "    ('regressor', lgb.LGBMRegressor(\n",
    "        n_estimators=1500, learning_rate=0.03, num_leaves=25, max_depth=5,\n",
    "        subsample=0.7, colsample_bytree=0.7,\n",
    "        objective='regression_l1', device='gpu', random_state=42, n_jobs=1, verbose=-1\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Modelo 3: CatBoost (El Profundo y Detallista)\n",
    "# Más profundo y con aprendizaje más lento para encontrar patrones complejos.\n",
    "catboost_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', cb.CatBoostRegressor(\n",
    "        n_estimators=2500, learning_rate=0.015, depth=9, l2_leaf_reg=4,\n",
    "        task_type='GPU', random_seed=42, verbose=0\n",
    "    ))\n",
    "])\n",
    "\n",
    "print(\"\\n✅ 3 Pipelines base definidos y listos.\")\n",
    "\n",
    "# --- 4. EVALUACIÓN DE TODOS LOS MODELOS BASE ---\n",
    "print(\"\\n--- 📈 Evaluando modelos base ---\")\n",
    "scores_report = {} \n",
    "\n",
    "# Evaluar XGBoost\n",
    "xgb_base_scores = cross_val_score(xgb_pipeline, X_full, y_full, cv=5, scoring='neg_root_mean_squared_error', n_jobs=1)\n",
    "scores_report['xgb_base_rmse'] = -xgb_base_scores.mean()\n",
    "print(f\"✅ XGBoost Base CV Score (RMSE): {scores_report.get('xgb_base_rmse'):.5f}\")\n",
    "\n",
    "# Evaluar LightGBM\n",
    "lgbm_base_scores = cross_val_score(lgbm_pipeline, X_full, y_full, cv=5, scoring='neg_root_mean_squared_error', n_jobs=1)\n",
    "scores_report['lgbm_base_rmse'] = -lgbm_base_scores.mean()\n",
    "print(f\"✅ LightGBM Base CV Score (RMSE): {scores_report.get('lgbm_base_rmse'):.5f}\")\n",
    "\n",
    "# Evaluar CatBoost\n",
    "catboost_base_scores = cross_val_score(catboost_pipeline, X_full, y_full, cv=5, scoring='neg_root_mean_squared_error', n_jobs=1)\n",
    "scores_report['catboost_base_rmse'] = -catboost_base_scores.mean()\n",
    "print(f\"✅ CatBoost Base CV Score (RMSE): {scores_report.get('catboost_base_rmse'):.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d6bd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================================\n",
    "# CELDA 4: CONSTRUCCIÓN DEL ENSAMBLE STACKING\n",
    "# =========================================================================\n",
    "\n",
    "# --- Construcción del Ensamble Final con 3 modelos base ---\n",
    "meta_model = Ridge(random_state=42)\n",
    "stacking_ensemble = StackingRegressor(\n",
    "    estimators=[\n",
    "        ('xgb', xgb_pipeline),\n",
    "        ('lgbm', lgbm_pipeline),\n",
    "        ('catboost', catboost_pipeline)\n",
    "    ],\n",
    "    final_estimator=meta_model, # Ridge sigue siendo el meta-modelo\n",
    "    cv=5,\n",
    "    n_jobs=1\n",
    ")\n",
    "print(\"\\n✅ Ensamble de Stacking con 3 modelos base definido y listo.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1af17b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================================\n",
    "# CELDA 5: ENTRENAMIENTO, PREDICCIÓN Y REPORTE FINAL\n",
    "# =========================================================================\n",
    "\n",
    "# --- EVALUACIÓN DEL ENSAMBLE FINAL ---\n",
    "print(\"\\n--- 📈 Evaluando el Ensamble de Stacking Final ---\")\n",
    "stacking_scores = cross_val_score(stacking_ensemble, X_full, y_full, cv=5, scoring='neg_root_mean_squared_error', n_jobs=1)\n",
    "scores_report['stacking_final_rmse'] = -stacking_scores.mean()\n",
    "print(f\"✅ Stacking Ensemble CV Score (RMSE): {scores_report.get('stacking_final_rmse'):.5f}\")\n",
    "\n",
    "\n",
    "# --- ENTRENAMIENTO FINAL DEL ENSAMBLE ---\n",
    "print(\"\\n--- ⚙️  Entrenando el ensamble final en TODO el dataset... ---\")\n",
    "stacking_ensemble.fit(X_full, y_full)\n",
    "print(\"✅ Ensamble entrenado con éxito.\")\n",
    "\n",
    "\n",
    "# --- PREDICCIÓN Y CREACIÓN DEL ARCHIVO DE SUBMISSION ---\n",
    "print(\"\\n--- 🧠 Realizando predicciones sobre el conjunto de test... ---\")\n",
    "test_predictions = stacking_ensemble.predict(X_test_full)\n",
    "submission_df = pd.DataFrame({'id': test_ids, 'accident_risk': test_predictions})\n",
    "submission_df['accident_risk'] = submission_df['accident_risk'].clip(0, 1)\n",
    "submission_path = 'submission_ensemble.csv'\n",
    "submission_df.to_csv(submission_path, index=False)\n",
    "print(f\"\\n🎉 ¡Éxito! Archivo de submission guardado en: {submission_path}\")\n",
    "\n",
    "\n",
    "# --- ESCRITURA DEL REPORTE FINAL EN UN ARCHIVO .TXT ---\n",
    "print(\"\\n--- 💾 Guardando reporte de rendimiento ---\")\n",
    "report_path = 'rendimiento_modelos.txt'\n",
    "with open(report_path, 'w') as f:\n",
    "    f.write(\"=\"*50 + \"\\n\")\n",
    "    f.write(\"      INFORME DE RENDIMIENTO DE MODELOS (RMSE)\\n\")\n",
    "    f.write(\"=\"*50 + \"\\n\\n\")\n",
    "    \n",
    "    def format_score(key):\n",
    "        score = scores_report.get(key)\n",
    "        if isinstance(score, float): return f\"{score:.5f}\"\n",
    "        return \"N/A\"\n",
    "\n",
    "    f.write(\"--- Modelos Base ---\\n\")\n",
    "    f.write(f\"XGBoost:      {format_score('xgb_base_rmse')}\\n\")\n",
    "    f.write(f\"LightGBM:     {format_score('lgbm_base_rmse')}\\n\")\n",
    "    f.write(f\"CatBoost:     {format_score('catboost_base_rmse')}\\n\")\n",
    "    f.write(f\"Ridge:        {format_score('ridge_base_rmse')}\\n\\n\")\n",
    "    \n",
    "    f.write(\"--- Modelo Final ---\\n\")\n",
    "    f.write(f\"Ensamble Stacking: {format_score('stacking_final_rmse')}\\n\\n\")\n",
    "    \n",
    "    f.write(\"=\"*50 + \"\\n\")\n",
    "    f.write(f\"Reporte generado el {pd.Timestamp.now(tz='America/Bogota').strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "\n",
    "print(f\"✅ Reporte guardado en: {report_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "596df565",
   "metadata": {},
   "source": [
    "# Resultados de entrenamiento\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "INFORME DE RENDIMIENTO DE MODELOS (RMSE)\n",
    "\n",
    "--- Modelos Base --- RMSE (CV 5-Folds)\n",
    "\n",
    "- XGBoost:                0.05309\n",
    "- LightGBM:               0.05326\n",
    "- CatBoost:               0.05310\n",
    "\n",
    "\n",
    "--- Modelo Final ---\n",
    "- Ensamble Stacking:      0.05306\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
