# Taller 1: Predicci√≥n de Riesgo de Accidentes

Este repositorio contiene el desarrollo del Taller 1, enfocado en la creaci√≥n de modelos de machine learning para predecir el riesgo de accidentes de tr√°fico. Se exploraron dos enfoques principales: un modelo lineal simple y un ensamble avanzado de stacking.

## üöÄ Resultados en la Competici√≥n

Los modelos fueron evaluados en la competici√≥n de Kaggle, obteniendo los siguientes resultados:

| Modelo | Score (RMSE) | Posici√≥n en Leaderboard |
| :--- | :---: | :---: |
| **Ensamble Stacking** | **0.05556** | **696** |
| Modelo Lineal (Ridge) | 0.07199 | 2559 |

---

## ü§ñ Comparaci√≥n de Modelos

### Modelo Lineal (Baseline)
Se implement√≥ un modelo de **Regresi√≥n Ridge** como punto de partida. Aunque es r√°pido y f√°cil de interpretar, su naturaleza lineal limita su capacidad para capturar las interacciones complejas y no lineales presentes en los datos, como la relaci√≥n entre el clima, la iluminaci√≥n y el tipo de v√≠a. Esto se reflej√≥ en un score de **0.07199**, ubic√°ndose en la posici√≥n **2559**.

### Ensamble Stacking (Modelo Avanzado)
Para mejorar el rendimiento, se construy√≥ un **ensamble de stacking**. Este enfoque es significativamente m√°s potente por las siguientes razones:

1.  **Combina Fortalezas**: El ensamble utiliz√≥ tres modelos base robustos (**XGBoost, LightGBM y CatBoost**). Cada uno de estos modelos es experto en identificar diferentes tipos de patrones en los datos.
2.  **Meta-aprendizaje**: En lugar de promediar las predicciones, el stacking a√±ade un "meta-modelo" (`Ridge`) que aprende a ponderar de forma inteligente las predicciones de los modelos base. Este "gerente" sabe cu√°ndo confiar m√°s en XGBoost, cu√°ndo en LightGBM, etc., seg√∫n el tipo de datos de entrada.
3.  **Reducci√≥n del Error**: Al combinar las perspectivas de m√∫ltiples modelos diversos, el ensamble es m√°s robusto y generaliza mejor, reduciendo el error de predicci√≥n.

Gracias a esta estrategia avanzada, el ensamble de stacking logr√≥ un score de **0.05556**, lo que nos posicion√≥ en el **lugar 696** del leaderboard, demostrando ser un enfoque muy superior para este problema.

---

## üõ†Ô∏è Estructura del Repositorio

* `/data`: Contiene los datasets de entrenamiento (`train.csv`) y prueba (`test.csv`).
* `punto1.ipynb` a `punto4.ipynb`: Notebooks con el desarrollo de la soluci√≥n, desde el an√°lisis exploratorio hasta el modelado final.
* `/submission files`: Contiene los archivos de env√≠o generados, incluyendo `submission_ensemble.csv` y `submission_lineal.csv`.
